{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOg7aOElEbENlIMQF+dzM3G"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":11,"metadata":{"id":"YRDP6AxyzCVz","executionInfo":{"status":"ok","timestamp":1709488400486,"user_tz":480,"elapsed":608,"user":{"displayName":"Youngsook Choi","userId":"07785096630634099789"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"1c7fd798-12e6-4da5-db50-3c67a00f38e6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Anthony Black\n","<tr class=\"per_game\">\n","<td>2022-23</td>\n","<td id=\"teamLinencaa_reg_Per_Game_1\"><a href=\"/ncaa/conferences/Southeastern-Conference/8/Arkansas/254/Rosters/2023\">Arkansas</a></td>\n","<td id=\"teamLinencaa_reg_Per_Game_1\">Fr</td>\n","<td>36</td>\n","<td>35</td>\n","<td>34.3</td>\n","<td>12.78</td>\n","<td>4.14</td>\n","<td>9.14</td>\n","<td>.453</td>\n","<td>0.78</td>\n","<td>2.58</td>\n","<td>.301</td>\n","<td>3.72</td>\n","<td>5.28</td>\n","<td>.705</td>\n","<td>1.25</td>\n","<td>3.81</td>\n","<td>5.06</td>\n","<td>3.92</td>\n","<td>2.06</td>\n","<td>0.61</td>\n","<td>3.03</td>\n","<td>2.58</td>\n","</tr>\n","['2022-23', 'Arkansas', 'Fr', '36', '35', '34.3', '12.78', '4.14', '9.14', '.453', '0.78', '2.58', '.301', '3.72', '5.28', '.705', '1.25', '3.81', '5.06', '3.92', '2.06', '0.61', '3.03', '2.58']\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-11-635d5a4a1186>:30: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n","  player_ncaa_per_game = soup.find('h2', text='NCAA Season Stats - Per Game')\n"]}],"source":["import csv\n","from urllib.request import urlopen\n","from bs4 import BeautifulSoup\n","import re\n","\n","url_list = ['https://basketball.realgm.com/player/Anthony-Black/Summary/176057']\n","\n","for url in url_list:\n","  page = urlopen(url)\n","  html_bytes = page.read()\n","  html = html_bytes.decode(\"utf-8\") # get string from the html page\n","\n","  # Parse through and collect the player's stats per game\n","  soup = BeautifulSoup(html, 'html.parser')\n","\n","  # Find the DIV tag containing \"profile-box\"\n","  player_profile = soup.find('div', class_ = 'profile-box')\n","  # Find the h2 tag\n","  h2_tag = player_profile.find_next('h2')\n","\n","  if h2_tag:\n","    # Extract only the name of the h2 tag, ignoring any child elements\n","    player_name = ''.join(h2_tag.contents[0::2]).strip()\n","    print(player_name)\n","  else:\n","    print(\"h2 tag not found in the HTML.\")\n","\n","  # Find the h2 tag containing \"NCAA Season Stats - Per Game\"\n","  player_ncaa_per_game = soup.find('h2', text='NCAA Season Stats - Per Game')\n","  # Find the table containing player stats\n","  player_table = player_ncaa_per_game.find_next('tbody')\n","\n","  if player_table:\n","    # Get all rows in the table except the header row\n","    player_per_game_rows = player_table.find_all('tr')[1:]\n","\n","    player_stats_table = player_table.find('tr', class_ = \"per_game\")\n","    print(player_stats_table)\n","\n","    if player_stats_table:\n","      # Get all columns in the table\n","      stats_cols = player_stats_table.find_all('td')\n","\n","      # Extract text content of each column and store in a list\n","      stats_data = [cell.get_text() for cell in stats_cols]\n","      print(stats_data)\n","\n","      # Prepend player name to stats_data list\n","      stats_data.insert(0, player_name)\n","      # Write the data to a CSV file\n","      with open('player_stats.csv', 'w', newline='') as csvfile:\n","        writer = csv.writer(csvfile)\n","        writer.writerow(['Player','Season', 'School', 'Class', 'GP', 'GS', 'MIN', 'PTS', 'FGM', 'FGA', 'FG%', '3PM', '3PA', '3P%', 'FTM', 'FTA', 'FT%', 'OFF', 'DEF', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF'])\n","        writer.writerow(stats_data)\n","    else:\n","      print(\"Player statistics table not found on the page.\")\n"]},{"cell_type":"code","source":["import csv ;import requests\n","from bs4 import BeautifulSoup\n","import csv\n","import re\n","\n","url_list = ['https://basketball.realgm.com/player/player/Summary/2',\n","            'https://basketball.realgm.com/player/player/Summary/1']\n","\n","for url in url_list:\n","    r = requests.get(url)\n","    soup = BeautifulSoup(r.text, 'html.parser')\n","\n","    player = soup.find_all('div', class_='wrapper clearfix container')[0]\n","\n","    playerprofile = re.sub(\n","        r'\\n\\s*\\n', r'\\n', player.get_text().strip(), flags=re.M)\n","\n","    output = playerprofile + \"\\n\""],"metadata":{"id":"nYLBMCIYhHhT","executionInfo":{"status":"ok","timestamp":1709438519039,"user_tz":480,"elapsed":2225,"user":{"displayName":"Youngsook Choi","userId":"07785096630634099789"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["# pip install pandas\n","import pandas as pd\n","dfs = pd.read_html('https://www.basketball-reference.com/teams/MIL/2023.html')\n","#dfs = pd.read_html('https://www.nba.com/stats/draft/history')\n","\n","stats = dfs[2].dropna()  # the third table in the page and remove the last row\n","print(stats.head())\n","print(len(stats))"],"metadata":{"id":"A2u353TNcVWg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# aim for https://stats.ncaa.org/player/index?game_sport_year_ctl_id=16060&stats_player_seq=2082498.0\n","\n","\n","#!/usr/bin/env python3\n","\"\"\"\n","Python webscrapping module.\n","\n","Webscrap teamrankings.com website to obtain a list of the top 68 basketball\n","teams and url references to use for webscrapping other websites for team stats.\n","\n","For each of the 68 teams, webscrap teamrankings.com and kenpom.com for lists\n","of 10 key stats, then write those stats to an existing Excel spreadsheet.\n","\"\"\"\n","import re\n","import time\n","from difflib import get_close_matches\n","from itertools import islice\n","\n","import pandas\n","import requests\n","from bs4 import BeautifulSoup\n","from openpyxl import load_workbook\n","\n","start = time.time()\n","# assign url to variable and use requests to get html\n","print('Getting a list of all teams.')\n","url = 'https://www.teamrankings.com/ncaa-tournament/bracketology/'\n","teams_page = requests.get(url)\n","teams = teams_page.content\n","\n","# parse html with BeautifulSoup\n","soup = BeautifulSoup(teams, 'html.parser')\n","\n","# scrap all team names and add to a dictionary\n","full_teams_list = {}\n","lst = soup.find_all('td', {'class': 'text-left'})\n","\n","for item in lst:\n","    team_name = item.find('a').text\n","    # scrap url reference for team name (e.g., 'gonzaga-bulldogs') and add to\n","    # dictionary\n","    url_ref = item.find('a')['href'][22:-13]\n","    full_teams_list[team_name] = url_ref\n","print('Done!')\n","\n","\n","def take(n, iterable):\n","    \"\"\"Return first n items of the iterable as a list.\"\"\"\n","    return list(islice(iterable, n))\n","\n","\n","# grab top 68 teams and create list of teams and list of url references\n","print('Cutting that list to the top 68 teams')\n","top_68 = take(68, full_teams_list.items())\n","teams_list = []\n","url_ref_list = []\n","for tup in top_68:\n","    teams_list.append(tup[0])\n","    url_ref_list.append(tup[1])\n","print('Done!')\n","\n","# build two lists of urls to scrap stats for each team\n","print('Building two lists of urls to parse')\n","stat_url_list = []\n","sos_url_list = []\n","for url in url_ref_list:\n","    stat_url_list.append('https://www.teamrankings.com/ncaa-basketball/team/' +\n","                         url + '/stats')\n","    sos_url_list.append('https://www.teamrankings.com/ncaa-basketball/team/' +\n","                        url + '/rankings')\n","print('Done!')\n","\n","print('Getting stats from teamrankings.com')\n","# create empty lists to hold stats\n","eFG = []\n","TO = []\n","OR = []\n","FT = []\n","deFG = []\n","dTO = []\n","DR = []\n","dFT = []\n","five = []\n","# loop through the first url list for each team to get the stats and add to the\n","# empty lists\n","print('First Four')\n","for stat in stat_url_list:\n","    stats_page = requests.get(stat)\n","    stats = stats_page.content\n","\n","    soup1 = BeautifulSoup(stats, 'html.parser')\n","\n","    numbers = soup1.find_all('td', {'class': 'nowrap'})\n","    # temporary list\n","    s = []\n","    for number in numbers:\n","        # this will add all the stats from the url, even those we don't need\n","        s.append(number.text)\n","    # use list indexing and slicing to add only the stats we want\n","    eFG.append(float(s[25][:4]))\n","    TO.append(float(s[125][:4]))\n","    OR.append(float(s[97][:4]))\n","    FT.append(float(s[29][:5]))\n","    deFG.append(float(s[27][:4]))\n","    dTO.append(float(s[127][:4]))\n","    DR.append(float(s[101][:4]))\n","    dFT.append(float(s[31][:5]))\n","\n","# same thing but for the second url list\n","print('Strength of Schedule')\n","for sos in sos_url_list:\n","    rankings_page = requests.get(sos)\n","    rankings = rankings_page.content\n","\n","    soup2 = BeautifulSoup(rankings, 'html.parser')\n","\n","    numbers2 = soup2.find_all('td', {'class': 'text-right'})\n","\n","    s1 = []\n","    for number2 in numbers2:\n","        s1.append(number2.text)\n","    five.append(float(s1[15]))\n","print('Done!')\n","\n","# assign url to variable and use requests to get html\n","print('Getting stats from kenpom.com')\n","url1 = 'https://kenpom.com/'\n","kp_page = requests.get(url1)\n","kp = kp_page.content\n","\n","# parse html with BeautifulSoup\n","soup3 = BeautifulSoup(kp, 'html.parser')\n","\n","# create lists of the team names and stats (again, all teams and stats)\n","left = soup3.find_all('td', {'class': 'td-left'})\n","names = soup3.find_all('a', {'href': re.compile(r'team\\.php\\?team=.+')})\n","s2 = []\n","n = []\n","print('Stats')\n","for number3 in left:\n","    s2.append(float(number3.text))\n","print('Teams')\n","for name in names:\n","    n.append(name.text)\n","\n","\n","def swap(old_team, new_team):\n","    \"\"\"Replace old_team with new_team for list n.\"\"\"\n","    i = n.index(old_team)\n","    n.remove(old_team)\n","    n.insert(i, new_team)\n","\n","\n","# replace team names so they match\n","swap('North Carolina', 'N Carolina')\n","swap('West Virginia', 'W Virginia')\n","swap('Saint Mary\\'s', 'St Marys')\n","swap('Miami FL', 'Miami (FL)')\n","swap('TCU', 'TX Christian')\n","swap('Virginia Tech', 'VA Tech')\n","swap('Ohio St.', 'Ohio State')\n","\n","# use list slicing to get only the stats we need and add to two new lists\n","adjo = s2[0::8]\n","adjd = s2[1::8]\n","# create a third list to hold the difference of lists one and two\n","diff = []\n","for o, d in zip(adjo, adjd):\n","    diff.append(round(float(o) - float(d), 1))\n","\n","print('Done!')\n","\n","# convert the four lists into a DataFrame object\n","df2 = pandas.DataFrame([n, adjo, adjd, diff]).T\n","# set the team name as the DataFrame index\n","df2 = df2.set_index(0)\n","\n","# convert the DataFrame to a dictionary, splitting the team names and stats\n","# into separate dictionaries\n","df3 = pandas.DataFrame.to_dict(df2, orient='split')\n","\n","\n","def getStats(team):\n","    \"\"\"Return list of stats for team if that team is found or return 0.0.\"\"\"\n","    if team in df3['index']:\n","        index = df3['index'].index(team)\n","        return df3['data'][index]\n","    elif len(get_close_matches(team, df3['index'], cutoff=0.92)) > 0:\n","        b = get_close_matches(team, df3['index'], cutoff=0.92)[0]\n","        index = df3['index'].index(b)\n","        return df3['data'][index]\n","    else:\n","        return [0.0, 0.0, 0.0]\n","\n","\n","# create new lists to hold the stats for the top 68 teams only\n","_adjo = []\n","_adjd = []\n","_diff = []\n","# use the getStats function to match team names from both websites and get the\n","# stats from kenpom.com for that team\n","print('Getting the right stats for the right teams')\n","for team in teams_list:\n","    _adjo.append(getStats(team)[0])\n","    _adjd.append(getStats(team)[1])\n","    _diff.append(getStats(team)[2])\n","\n","# load workbook object from Excel spreadsheet\n","print('Adding to NCAA Bracket Spreadsheet')\n","wb = load_workbook(filename='NCAA Bracket Spreadsheet-base.xlsx')\n","sheet = wb['Provided Ranking']\n","\n","\n","def writeToExcel(list, col):\n","    \"\"\"Write data to the Excel spreadsheet.\"\"\"\n","    counter = 0\n","    for rowNum in range(3, 71):\n","        sheet.cell(row=rowNum, column=col).value = list[counter]\n","        counter += 1\n","\n","\n","# use writeToExcel function to stats from all 13 lists to the Excel spreadsheet\n","writeToExcel(teams_list, 2)\n","writeToExcel(eFG, 3)\n","writeToExcel(TO, 4)\n","writeToExcel(OR, 5)\n","writeToExcel(FT, 6)\n","writeToExcel(deFG, 7)\n","writeToExcel(dTO, 8)\n","writeToExcel(DR, 9)\n","writeToExcel(dFT, 10)\n","writeToExcel(five, 14)\n","writeToExcel(_adjo, 11)\n","writeToExcel(_adjd, 12)\n","writeToExcel(_diff, 13)\n","\n","# save copy of Excel spreadsheet\n","wb.save(filename='NCAA Bracket Spreadsheet-final.xlsx')\n","print('Done!')\n","\n","end = time.time()\n","total_time = round((end - start) / 60, 2)\n","print('All steps complete.\\nScript completed in %s minutes.\\nGood luck!' %\n","      total_time)"],"metadata":{"id":"RSecbqFmcXZg"},"execution_count":null,"outputs":[]}]}